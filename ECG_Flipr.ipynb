{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLgxJV5eBzx"
      },
      "source": [
        "## **STEP-1: IMPORTING LIBRARIES AND DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **INSTALLING HEARTPY LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "x6T8yt0MW50w",
        "outputId": "e4852277-3f67-4dd8-c24e-8c5cdc67b8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: heartpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.7)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from heartpy) (3.5.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from heartpy) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from heartpy) (1.22.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (4.34.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (1.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (9.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->heartpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->heartpy) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install heartpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.8.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.22.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **IMPORTING BASIC LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "dWTRet5lWjCp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import heartpy as hp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **IMPORTING MACHINE LEARNING LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "UcR8u2GzWjCx"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dw-yQGplWjCy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>8991</th>\n",
              "      <th>8992</th>\n",
              "      <th>8993</th>\n",
              "      <th>8994</th>\n",
              "      <th>8995</th>\n",
              "      <th>8996</th>\n",
              "      <th>8997</th>\n",
              "      <th>8998</th>\n",
              "      <th>8999</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-127</td>\n",
              "      <td>-162</td>\n",
              "      <td>-197</td>\n",
              "      <td>-229</td>\n",
              "      <td>-245</td>\n",
              "      <td>-254</td>\n",
              "      <td>-261</td>\n",
              "      <td>-265</td>\n",
              "      <td>-268</td>\n",
              "      <td>-268</td>\n",
              "      <td>...</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>-7</td>\n",
              "      <td>-12</td>\n",
              "      <td>-15</td>\n",
              "      <td>-18</td>\n",
              "      <td>-22</td>\n",
              "      <td>-21</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>128</td>\n",
              "      <td>157</td>\n",
              "      <td>189</td>\n",
              "      <td>226</td>\n",
              "      <td>250</td>\n",
              "      <td>257</td>\n",
              "      <td>262</td>\n",
              "      <td>265</td>\n",
              "      <td>268</td>\n",
              "      <td>269</td>\n",
              "      <td>...</td>\n",
              "      <td>-5</td>\n",
              "      <td>-3</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>519</td>\n",
              "      <td>619</td>\n",
              "      <td>723</td>\n",
              "      <td>827</td>\n",
              "      <td>914</td>\n",
              "      <td>956</td>\n",
              "      <td>955</td>\n",
              "      <td>934</td>\n",
              "      <td>920</td>\n",
              "      <td>900</td>\n",
              "      <td>...</td>\n",
              "      <td>1144</td>\n",
              "      <td>1055</td>\n",
              "      <td>866</td>\n",
              "      <td>632</td>\n",
              "      <td>403</td>\n",
              "      <td>224</td>\n",
              "      <td>116</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-266</td>\n",
              "      <td>-316</td>\n",
              "      <td>-367</td>\n",
              "      <td>-407</td>\n",
              "      <td>-423</td>\n",
              "      <td>-423</td>\n",
              "      <td>-401</td>\n",
              "      <td>-367</td>\n",
              "      <td>-329</td>\n",
              "      <td>-305</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>73</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>62</td>\n",
              "      <td>51</td>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>...</td>\n",
              "      <td>-456</td>\n",
              "      <td>-263</td>\n",
              "      <td>-46</td>\n",
              "      <td>133</td>\n",
              "      <td>227</td>\n",
              "      <td>257</td>\n",
              "      <td>236</td>\n",
              "      <td>174</td>\n",
              "      <td>84</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 9001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6    7    8    9  ...  8991  8992  8993  \\\n",
              "0 -127 -162 -197 -229 -245 -254 -261 -265 -268 -268  ...    19     8     0   \n",
              "1  128  157  189  226  250  257  262  265  268  269  ...    -5    -3    -2   \n",
              "2  519  619  723  827  914  956  955  934  920  900  ...  1144  1055   866   \n",
              "3 -266 -316 -367 -407 -423 -423 -401 -367 -329 -305  ...    74    73    69   \n",
              "4   21   22   24   26   28   31   32   34   34   35  ...  -456  -263   -46   \n",
              "\n",
              "   8994  8995  8996  8997  8998  8999  Classification  \n",
              "0    -7   -12   -15   -18   -22   -21               N  \n",
              "1    -1    -1     0     0     1     2               N  \n",
              "2   632   403   224   116    17    18               A  \n",
              "3    68    66    62    51    34    21               N  \n",
              "4   133   227   257   236   174    84               N  \n",
              "\n",
              "[5 rows x 9001 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_raw = pd.read_csv(\"ECG_training.csv\", index_col=[0])\n",
        "data_raw.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i5-IcXZFWjC5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>8991</th>\n",
              "      <th>8992</th>\n",
              "      <th>8993</th>\n",
              "      <th>8994</th>\n",
              "      <th>8995</th>\n",
              "      <th>8996</th>\n",
              "      <th>8997</th>\n",
              "      <th>8998</th>\n",
              "      <th>8999</th>\n",
              "      <th>Classification_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-127</td>\n",
              "      <td>-162</td>\n",
              "      <td>-197</td>\n",
              "      <td>-229</td>\n",
              "      <td>-245</td>\n",
              "      <td>-254</td>\n",
              "      <td>-261</td>\n",
              "      <td>-265</td>\n",
              "      <td>-268</td>\n",
              "      <td>-268</td>\n",
              "      <td>...</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>-7</td>\n",
              "      <td>-12</td>\n",
              "      <td>-15</td>\n",
              "      <td>-18</td>\n",
              "      <td>-22</td>\n",
              "      <td>-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>128</td>\n",
              "      <td>157</td>\n",
              "      <td>189</td>\n",
              "      <td>226</td>\n",
              "      <td>250</td>\n",
              "      <td>257</td>\n",
              "      <td>262</td>\n",
              "      <td>265</td>\n",
              "      <td>268</td>\n",
              "      <td>269</td>\n",
              "      <td>...</td>\n",
              "      <td>-5</td>\n",
              "      <td>-3</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>519</td>\n",
              "      <td>619</td>\n",
              "      <td>723</td>\n",
              "      <td>827</td>\n",
              "      <td>914</td>\n",
              "      <td>956</td>\n",
              "      <td>955</td>\n",
              "      <td>934</td>\n",
              "      <td>920</td>\n",
              "      <td>900</td>\n",
              "      <td>...</td>\n",
              "      <td>1144</td>\n",
              "      <td>1055</td>\n",
              "      <td>866</td>\n",
              "      <td>632</td>\n",
              "      <td>403</td>\n",
              "      <td>224</td>\n",
              "      <td>116</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-266</td>\n",
              "      <td>-316</td>\n",
              "      <td>-367</td>\n",
              "      <td>-407</td>\n",
              "      <td>-423</td>\n",
              "      <td>-423</td>\n",
              "      <td>-401</td>\n",
              "      <td>-367</td>\n",
              "      <td>-329</td>\n",
              "      <td>-305</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>73</td>\n",
              "      <td>69</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>62</td>\n",
              "      <td>51</td>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>...</td>\n",
              "      <td>-456</td>\n",
              "      <td>-263</td>\n",
              "      <td>-46</td>\n",
              "      <td>133</td>\n",
              "      <td>227</td>\n",
              "      <td>257</td>\n",
              "      <td>236</td>\n",
              "      <td>174</td>\n",
              "      <td>84</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>347</td>\n",
              "      <td>378</td>\n",
              "      <td>410</td>\n",
              "      <td>540</td>\n",
              "      <td>695</td>\n",
              "      <td>736</td>\n",
              "      <td>751</td>\n",
              "      <td>778</td>\n",
              "      <td>849</td>\n",
              "      <td>803</td>\n",
              "      <td>...</td>\n",
              "      <td>241</td>\n",
              "      <td>267</td>\n",
              "      <td>252</td>\n",
              "      <td>115</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>-80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3496</th>\n",
              "      <td>-59</td>\n",
              "      <td>-71</td>\n",
              "      <td>-87</td>\n",
              "      <td>-104</td>\n",
              "      <td>-111</td>\n",
              "      <td>-114</td>\n",
              "      <td>-117</td>\n",
              "      <td>-119</td>\n",
              "      <td>-120</td>\n",
              "      <td>-121</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>92</td>\n",
              "      <td>63</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3497</th>\n",
              "      <td>-60</td>\n",
              "      <td>-83</td>\n",
              "      <td>-106</td>\n",
              "      <td>-128</td>\n",
              "      <td>-145</td>\n",
              "      <td>-155</td>\n",
              "      <td>-163</td>\n",
              "      <td>-168</td>\n",
              "      <td>-173</td>\n",
              "      <td>-177</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>42</td>\n",
              "      <td>34</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>-5</td>\n",
              "      <td>-8</td>\n",
              "      <td>-9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3498</th>\n",
              "      <td>582</td>\n",
              "      <td>702</td>\n",
              "      <td>807</td>\n",
              "      <td>893</td>\n",
              "      <td>962</td>\n",
              "      <td>997</td>\n",
              "      <td>984</td>\n",
              "      <td>945</td>\n",
              "      <td>927</td>\n",
              "      <td>915</td>\n",
              "      <td>...</td>\n",
              "      <td>-25</td>\n",
              "      <td>-23</td>\n",
              "      <td>-13</td>\n",
              "      <td>-38</td>\n",
              "      <td>-65</td>\n",
              "      <td>-65</td>\n",
              "      <td>-50</td>\n",
              "      <td>-42</td>\n",
              "      <td>-46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499</th>\n",
              "      <td>162</td>\n",
              "      <td>145</td>\n",
              "      <td>97</td>\n",
              "      <td>27</td>\n",
              "      <td>-36</td>\n",
              "      <td>-64</td>\n",
              "      <td>-90</td>\n",
              "      <td>-89</td>\n",
              "      <td>-37</td>\n",
              "      <td>61</td>\n",
              "      <td>...</td>\n",
              "      <td>-226</td>\n",
              "      <td>-217</td>\n",
              "      <td>-196</td>\n",
              "      <td>-157</td>\n",
              "      <td>-128</td>\n",
              "      <td>-104</td>\n",
              "      <td>-76</td>\n",
              "      <td>-51</td>\n",
              "      <td>-30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3500 rows × 9001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9  ...  8991  8992  8993  \\\n",
              "0    -127 -162 -197 -229 -245 -254 -261 -265 -268 -268  ...    19     8     0   \n",
              "1     128  157  189  226  250  257  262  265  268  269  ...    -5    -3    -2   \n",
              "2     519  619  723  827  914  956  955  934  920  900  ...  1144  1055   866   \n",
              "3    -266 -316 -367 -407 -423 -423 -401 -367 -329 -305  ...    74    73    69   \n",
              "4      21   22   24   26   28   31   32   34   34   35  ...  -456  -263   -46   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
              "3495  347  378  410  540  695  736  751  778  849  803  ...   241   267   252   \n",
              "3496  -59  -71  -87 -104 -111 -114 -117 -119 -120 -121  ...   120    92    63   \n",
              "3497  -60  -83 -106 -128 -145 -155 -163 -168 -173 -177  ...    52    47    42   \n",
              "3498  582  702  807  893  962  997  984  945  927  915  ...   -25   -23   -13   \n",
              "3499  162  145   97   27  -36  -64  -90  -89  -37   61  ...  -226  -217  -196   \n",
              "\n",
              "      8994  8995  8996  8997  8998  8999  Classification_N  \n",
              "0       -7   -12   -15   -18   -22   -21                 1  \n",
              "1       -1    -1     0     0     1     2                 1  \n",
              "2      632   403   224   116    17    18                 0  \n",
              "3       68    66    62    51    34    21                 1  \n",
              "4      133   227   257   236   174    84                 1  \n",
              "...    ...   ...   ...   ...   ...   ...               ...  \n",
              "3495   115    10     1    37    26   -80                 1  \n",
              "3496    32    16     7     2     0    -4                 1  \n",
              "3497    34    18     5    -5    -8    -9                 1  \n",
              "3498   -38   -65   -65   -50   -42   -46                 1  \n",
              "3499  -157  -128  -104   -76   -51   -30                 1  \n",
              "\n",
              "[3500 rows x 9001 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass1 = pd.get_dummies(data_raw, columns = ['Classification'], drop_first=True)\n",
        "data_pass1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRojO1L0eI62"
      },
      "source": [
        "## **PART-2: EDA Analysis and Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **COUNTING NULL VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VrzRM4lXWjDC",
        "outputId": "4f4ee436-8caf-4542-ce41-8654f98acabe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                   0\n",
              "1                   0\n",
              "2                   0\n",
              "3                   0\n",
              "4                   0\n",
              "                   ..\n",
              "8996                0\n",
              "8997                0\n",
              "8998                0\n",
              "8999                0\n",
              "Classification_N    0\n",
              "Length: 9001, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **FEATURE EXTRACTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EdC3KtbgWjDD",
        "outputId": "082b7e29-b2db-41f6-c689-42ebe2e6b01c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:5246: RuntimeWarning: Mean of empty slice.\n",
            "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3757: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\interpolate\\_fitpack2.py:280: UserWarning: \n",
            "The maximal number of iterations maxit (set to 20 by the program)\n",
            "allowed for finding a smoothing spline with fp=s has been reached: s\n",
            "too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  warnings.warn(message)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23576\\4272339245.py:5: UserWarning: Warning: converting a masked element to nan.\n",
            "  data_pass2.append(np.array(values[0:-1]))\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\interpolate\\_fitpack2.py:280: UserWarning: \n",
            "A theoretically impossible result was found during the iteration\n",
            "process for finding a smoothing spline with fp = s: s too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "data_pass2 = []\n",
        "for i in range(0, 3500):\n",
        "    wp, measures = hp.process(data_pass1.iloc[i, :-1], sample_rate = 300.0, clean_rr = True,clean_rr_method='z-score',bpmmax=2000,bpmmin=-1000)\n",
        "    values = [i for i in list(measures.values())]\n",
        "    data_pass2.append(np.array(values[0:-1]))\n",
        "data_pass2 = np.array(data_pass2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **ADDING LAST COLUMN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tloQj-OZWjDF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.965597</td>\n",
              "      <td>759.824561</td>\n",
              "      <td>32.308341</td>\n",
              "      <td>13.039216</td>\n",
              "      <td>23.466009</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>16.585877</td>\n",
              "      <td>43.207663</td>\n",
              "      <td>2251.381471</td>\n",
              "      <td>0.383864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>358.096197</td>\n",
              "      <td>167.552743</td>\n",
              "      <td>144.744509</td>\n",
              "      <td>140.973203</td>\n",
              "      <td>223.148951</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>103.333333</td>\n",
              "      <td>157.705144</td>\n",
              "      <td>138.037173</td>\n",
              "      <td>68389.871397</td>\n",
              "      <td>1.142483</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.425412</td>\n",
              "      <td>931.309524</td>\n",
              "      <td>169.711097</td>\n",
              "      <td>133.625235</td>\n",
              "      <td>219.979603</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>155.330156</td>\n",
              "      <td>183.697974</td>\n",
              "      <td>89641.686245</td>\n",
              "      <td>0.845574</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>151.840491</td>\n",
              "      <td>395.151515</td>\n",
              "      <td>179.203421</td>\n",
              "      <td>142.993395</td>\n",
              "      <td>360.872400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>254.442310</td>\n",
              "      <td>130.290274</td>\n",
              "      <td>104148.063640</td>\n",
              "      <td>1.952888</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62.666821</td>\n",
              "      <td>957.444444</td>\n",
              "      <td>51.766451</td>\n",
              "      <td>20.782041</td>\n",
              "      <td>29.980837</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>20.973468</td>\n",
              "      <td>69.332834</td>\n",
              "      <td>4568.346982</td>\n",
              "      <td>0.302504</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1           2           3           4         5  \\\n",
              "0   78.965597  759.824561   32.308341   13.039216   23.466009  0.411765   \n",
              "1  358.096197  167.552743  144.744509  140.973203  223.148951  0.893939   \n",
              "2   64.425412  931.309524  169.711097  133.625235  219.979603  0.923077   \n",
              "3  151.840491  395.151515  179.203421  142.993395  360.872400  1.000000   \n",
              "4   62.666821  957.444444   51.766451   20.782041   29.980837  0.413793   \n",
              "\n",
              "          6           7           8           9             10        11  \\\n",
              "0  0.029412   26.666667   16.585877   43.207663    2251.381471  0.383864   \n",
              "1  0.803030  103.333333  157.705144  138.037173   68389.871397  1.142483   \n",
              "2  0.807692  135.000000  155.330156  183.697974   89641.686245  0.845574   \n",
              "3  1.000000  140.000000  254.442310  130.290274  104148.063640  1.952888   \n",
              "4  0.103448   45.000000   20.973468   69.332834    4568.346982  0.302504   \n",
              "\n",
              "   Classification  \n",
              "0               1  \n",
              "1               1  \n",
              "2               0  \n",
              "3               1  \n",
              "4               1  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass3 = pd.DataFrame(data_pass2)\n",
        "data_pass3['Classification'] = data_pass1['Classification_N']\n",
        "data_pass3.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **REMOVING NULLS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h_IQtEDbWjDI",
        "outputId": "8ff6f44c-7d44-4ff9-dd2f-62ce662b1b6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                  10\n",
              "1                  10\n",
              "2                  10\n",
              "3                  68\n",
              "4                  68\n",
              "5                  68\n",
              "6                  68\n",
              "7                  10\n",
              "8                  68\n",
              "9                  68\n",
              "10                 68\n",
              "11                231\n",
              "Classification      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass3.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F7iePSK1WjDK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                 0\n",
              "1                 0\n",
              "2                 0\n",
              "3                 0\n",
              "4                 0\n",
              "5                 0\n",
              "6                 0\n",
              "7                 0\n",
              "8                 0\n",
              "9                 0\n",
              "10                0\n",
              "11                0\n",
              "Classification    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass4 = data_pass3.dropna()\n",
        "data_pass4.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **REPLACING INFINITELY LARGE VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.965597</td>\n",
              "      <td>759.824561</td>\n",
              "      <td>32.308341</td>\n",
              "      <td>13.039216</td>\n",
              "      <td>23.466009</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>16.585877</td>\n",
              "      <td>43.207663</td>\n",
              "      <td>2251.381471</td>\n",
              "      <td>0.383864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>358.096197</td>\n",
              "      <td>167.552743</td>\n",
              "      <td>144.744509</td>\n",
              "      <td>140.973203</td>\n",
              "      <td>223.148951</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>103.333333</td>\n",
              "      <td>157.705144</td>\n",
              "      <td>138.037173</td>\n",
              "      <td>68389.871397</td>\n",
              "      <td>1.142483</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.425412</td>\n",
              "      <td>931.309524</td>\n",
              "      <td>169.711097</td>\n",
              "      <td>133.625235</td>\n",
              "      <td>219.979603</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>155.330156</td>\n",
              "      <td>183.697974</td>\n",
              "      <td>89641.686245</td>\n",
              "      <td>0.845574</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>151.840491</td>\n",
              "      <td>395.151515</td>\n",
              "      <td>179.203421</td>\n",
              "      <td>142.993395</td>\n",
              "      <td>360.872400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>254.442310</td>\n",
              "      <td>130.290274</td>\n",
              "      <td>104148.063640</td>\n",
              "      <td>1.952888</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62.666821</td>\n",
              "      <td>957.444444</td>\n",
              "      <td>51.766451</td>\n",
              "      <td>20.782041</td>\n",
              "      <td>29.980837</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>20.973468</td>\n",
              "      <td>69.332834</td>\n",
              "      <td>4568.346982</td>\n",
              "      <td>0.302504</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>277.877698</td>\n",
              "      <td>215.922330</td>\n",
              "      <td>142.097807</td>\n",
              "      <td>118.393358</td>\n",
              "      <td>210.230370</td>\n",
              "      <td>0.946809</td>\n",
              "      <td>0.861702</td>\n",
              "      <td>116.666667</td>\n",
              "      <td>148.653017</td>\n",
              "      <td>125.457157</td>\n",
              "      <td>58589.398821</td>\n",
              "      <td>1.184891</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>183.073011</td>\n",
              "      <td>327.738095</td>\n",
              "      <td>151.683813</td>\n",
              "      <td>98.921107</td>\n",
              "      <td>254.435587</td>\n",
              "      <td>0.976744</td>\n",
              "      <td>0.953488</td>\n",
              "      <td>131.666667</td>\n",
              "      <td>179.874513</td>\n",
              "      <td>121.474451</td>\n",
              "      <td>68644.295126</td>\n",
              "      <td>1.480760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>237.105751</td>\n",
              "      <td>253.051643</td>\n",
              "      <td>196.085117</td>\n",
              "      <td>150.753119</td>\n",
              "      <td>328.476105</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>176.666667</td>\n",
              "      <td>231.333854</td>\n",
              "      <td>150.012969</td>\n",
              "      <td>109022.935841</td>\n",
              "      <td>1.542092</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>82.389289</td>\n",
              "      <td>728.250000</td>\n",
              "      <td>42.752437</td>\n",
              "      <td>7.964698</td>\n",
              "      <td>14.088950</td>\n",
              "      <td>0.108108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.333333</td>\n",
              "      <td>9.789606</td>\n",
              "      <td>57.033645</td>\n",
              "      <td>1754.067054</td>\n",
              "      <td>0.171646</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>251.508415</td>\n",
              "      <td>238.560606</td>\n",
              "      <td>136.783759</td>\n",
              "      <td>118.538512</td>\n",
              "      <td>198.954890</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>140.629997</td>\n",
              "      <td>136.710614</td>\n",
              "      <td>60399.045458</td>\n",
              "      <td>1.028669</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3267 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2           3           4         5  \\\n",
              "0      78.965597  759.824561   32.308341   13.039216   23.466009  0.411765   \n",
              "1     358.096197  167.552743  144.744509  140.973203  223.148951  0.893939   \n",
              "2      64.425412  931.309524  169.711097  133.625235  219.979603  0.923077   \n",
              "3     151.840491  395.151515  179.203421  142.993395  360.872400  1.000000   \n",
              "4      62.666821  957.444444   51.766451   20.782041   29.980837  0.413793   \n",
              "...          ...         ...         ...         ...         ...       ...   \n",
              "3264  277.877698  215.922330  142.097807  118.393358  210.230370  0.946809   \n",
              "3265  183.073011  327.738095  151.683813   98.921107  254.435587  0.976744   \n",
              "3266  237.105751  253.051643  196.085117  150.753119  328.476105  0.931034   \n",
              "3267   82.389289  728.250000   42.752437    7.964698   14.088950  0.108108   \n",
              "3268  251.508415  238.560606  136.783759  118.538512  198.954890  0.948718   \n",
              "\n",
              "             6           7           8           9             10        11  \\\n",
              "0     0.029412   26.666667   16.585877   43.207663    2251.381471  0.383864   \n",
              "1     0.803030  103.333333  157.705144  138.037173   68389.871397  1.142483   \n",
              "2     0.807692  135.000000  155.330156  183.697974   89641.686245  0.845574   \n",
              "3     1.000000  140.000000  254.442310  130.290274  104148.063640  1.952888   \n",
              "4     0.103448   45.000000   20.973468   69.332834    4568.346982  0.302504   \n",
              "...        ...         ...         ...         ...            ...       ...   \n",
              "3264  0.861702  116.666667  148.653017  125.457157   58589.398821  1.184891   \n",
              "3265  0.953488  131.666667  179.874513  121.474451   68644.295126  1.480760   \n",
              "3266  0.931034  176.666667  231.333854  150.012969  109022.935841  1.542092   \n",
              "3267  0.000000   18.333333    9.789606   57.033645    1754.067054  0.171646   \n",
              "3268  0.782051  115.000000  140.629997  136.710614   60399.045458  1.028669   \n",
              "\n",
              "      Classification  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "3264               1  \n",
              "3265               1  \n",
              "3266               1  \n",
              "3267               1  \n",
              "3268               1  \n",
              "\n",
              "[3267 rows x 13 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass5 = data_pass4.replace((np.inf, -np.inf, np.nan), np.nan).reset_index(drop=True)\n",
        "data_pass5.dropna(inplace=True)\n",
        "data_pass5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **CHECKING FOR IMBALANCE IN DATASET AND BALANCING IT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hQFYyuw1WjDO",
        "outputId": "f5d07a27-b11f-49ce-876f-2da2a4b04dd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification\n",
              "1    2865\n",
              "0     402\n",
              "dtype: int64"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass5.value_counts('Classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SREam3qRWjDQ"
      },
      "outputs": [],
      "source": [
        "smote_balancer = SMOTE(sampling_strategy='minority')\n",
        "X_balanced, Y_balanced = smote_balancer.fit_resample(data_pass5.drop('Classification', axis=1), data_pass5['Classification'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yXcffjjDWjDQ",
        "outputId": "1c768f6b-039e-41b9-d13b-e911c746c94d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.965597</td>\n",
              "      <td>759.824561</td>\n",
              "      <td>32.308341</td>\n",
              "      <td>13.039216</td>\n",
              "      <td>23.466009</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>16.585877</td>\n",
              "      <td>43.207663</td>\n",
              "      <td>2251.381471</td>\n",
              "      <td>0.383864</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>358.096197</td>\n",
              "      <td>167.552743</td>\n",
              "      <td>144.744509</td>\n",
              "      <td>140.973203</td>\n",
              "      <td>223.148951</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>103.333333</td>\n",
              "      <td>157.705144</td>\n",
              "      <td>138.037173</td>\n",
              "      <td>68389.871397</td>\n",
              "      <td>1.142483</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.425412</td>\n",
              "      <td>931.309524</td>\n",
              "      <td>169.711097</td>\n",
              "      <td>133.625235</td>\n",
              "      <td>219.979603</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>155.330156</td>\n",
              "      <td>183.697974</td>\n",
              "      <td>89641.686245</td>\n",
              "      <td>0.845574</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>151.840491</td>\n",
              "      <td>395.151515</td>\n",
              "      <td>179.203421</td>\n",
              "      <td>142.993395</td>\n",
              "      <td>360.872400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>254.442310</td>\n",
              "      <td>130.290274</td>\n",
              "      <td>104148.063640</td>\n",
              "      <td>1.952888</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62.666821</td>\n",
              "      <td>957.444444</td>\n",
              "      <td>51.766451</td>\n",
              "      <td>20.782041</td>\n",
              "      <td>29.980837</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>20.973468</td>\n",
              "      <td>69.332834</td>\n",
              "      <td>4568.346982</td>\n",
              "      <td>0.302504</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5725</th>\n",
              "      <td>141.303729</td>\n",
              "      <td>425.311547</td>\n",
              "      <td>158.433293</td>\n",
              "      <td>140.284849</td>\n",
              "      <td>253.904568</td>\n",
              "      <td>0.895792</td>\n",
              "      <td>0.883611</td>\n",
              "      <td>106.616956</td>\n",
              "      <td>178.706155</td>\n",
              "      <td>101.846894</td>\n",
              "      <td>55818.007689</td>\n",
              "      <td>1.822692</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5726</th>\n",
              "      <td>99.078065</td>\n",
              "      <td>629.841052</td>\n",
              "      <td>111.406827</td>\n",
              "      <td>90.180824</td>\n",
              "      <td>147.888124</td>\n",
              "      <td>0.848684</td>\n",
              "      <td>0.661670</td>\n",
              "      <td>88.087074</td>\n",
              "      <td>104.439996</td>\n",
              "      <td>116.198283</td>\n",
              "      <td>37869.320909</td>\n",
              "      <td>0.910865</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>196.930645</td>\n",
              "      <td>309.018596</td>\n",
              "      <td>172.397470</td>\n",
              "      <td>146.851468</td>\n",
              "      <td>271.641547</td>\n",
              "      <td>0.913915</td>\n",
              "      <td>0.816843</td>\n",
              "      <td>134.721917</td>\n",
              "      <td>191.986030</td>\n",
              "      <td>153.298848</td>\n",
              "      <td>92469.988505</td>\n",
              "      <td>1.252347</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5728</th>\n",
              "      <td>86.984788</td>\n",
              "      <td>746.031269</td>\n",
              "      <td>132.585040</td>\n",
              "      <td>107.199920</td>\n",
              "      <td>234.424149</td>\n",
              "      <td>0.950186</td>\n",
              "      <td>0.852421</td>\n",
              "      <td>118.763835</td>\n",
              "      <td>165.144165</td>\n",
              "      <td>112.240481</td>\n",
              "      <td>58231.537424</td>\n",
              "      <td>1.471375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5729</th>\n",
              "      <td>74.561466</td>\n",
              "      <td>807.441936</td>\n",
              "      <td>60.522537</td>\n",
              "      <td>36.418295</td>\n",
              "      <td>76.254318</td>\n",
              "      <td>0.900172</td>\n",
              "      <td>0.622404</td>\n",
              "      <td>39.293523</td>\n",
              "      <td>53.679278</td>\n",
              "      <td>59.379751</td>\n",
              "      <td>10006.235171</td>\n",
              "      <td>0.905383</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5730 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2           3           4         5  \\\n",
              "0      78.965597  759.824561   32.308341   13.039216   23.466009  0.411765   \n",
              "1     358.096197  167.552743  144.744509  140.973203  223.148951  0.893939   \n",
              "2      64.425412  931.309524  169.711097  133.625235  219.979603  0.923077   \n",
              "3     151.840491  395.151515  179.203421  142.993395  360.872400  1.000000   \n",
              "4      62.666821  957.444444   51.766451   20.782041   29.980837  0.413793   \n",
              "...          ...         ...         ...         ...         ...       ...   \n",
              "5725  141.303729  425.311547  158.433293  140.284849  253.904568  0.895792   \n",
              "5726   99.078065  629.841052  111.406827   90.180824  147.888124  0.848684   \n",
              "5727  196.930645  309.018596  172.397470  146.851468  271.641547  0.913915   \n",
              "5728   86.984788  746.031269  132.585040  107.199920  234.424149  0.950186   \n",
              "5729   74.561466  807.441936   60.522537   36.418295   76.254318  0.900172   \n",
              "\n",
              "             6           7           8           9             10        11  \\\n",
              "0     0.029412   26.666667   16.585877   43.207663    2251.381471  0.383864   \n",
              "1     0.803030  103.333333  157.705144  138.037173   68389.871397  1.142483   \n",
              "2     0.807692  135.000000  155.330156  183.697974   89641.686245  0.845574   \n",
              "3     1.000000  140.000000  254.442310  130.290274  104148.063640  1.952888   \n",
              "4     0.103448   45.000000   20.973468   69.332834    4568.346982  0.302504   \n",
              "...        ...         ...         ...         ...            ...       ...   \n",
              "5725  0.883611  106.616956  178.706155  101.846894   55818.007689  1.822692   \n",
              "5726  0.661670   88.087074  104.439996  116.198283   37869.320909  0.910865   \n",
              "5727  0.816843  134.721917  191.986030  153.298848   92469.988505  1.252347   \n",
              "5728  0.852421  118.763835  165.144165  112.240481   58231.537424  1.471375   \n",
              "5729  0.622404   39.293523   53.679278   59.379751   10006.235171  0.905383   \n",
              "\n",
              "      Classification  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "5725               0  \n",
              "5726               0  \n",
              "5727               0  \n",
              "5728               0  \n",
              "5729               0  \n",
              "\n",
              "[5730 rows x 13 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass6 = pd.DataFrame(X_balanced)\n",
        "data_pass6['Classification'] = Y_balanced\n",
        "data_pass6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Y_HAVgysWjDR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification\n",
              "0    2865\n",
              "1    2865\n",
              "dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pass6.value_counts('Classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **SCALING THE DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CHECKING WHICH SCALING WORKS BEST ON THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gwloMlBjWjDR",
        "outputId": "c317409a-7648-4e0e-e4e2-f3a21dddd07a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "scaler_minmax = MinMaxScaler()\n",
        "scaler_standard = StandardScaler()\n",
        "scaler_robust = RobustScaler()\n",
        "\n",
        "X_scaled1 = scaler_minmax.fit_transform(X_balanced)\n",
        "X_scaled2 = scaler_standard.fit_transform(X_balanced)\n",
        "X_scaled3 = scaler_robust.fit_transform(X_balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **DEFINING MODELS AND THEIR HYPERPARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'SVM_Classifier': SVC(),\n",
        "    'KNN_Classifier': KNeighborsClassifier(),\n",
        "    'ExtraTreesClassifier': ExtraTreesClassifier()\n",
        "}\n",
        "\n",
        "model_params = {\n",
        "    'LogisticRegression': {\n",
        "        'penalty': ['l1', 'none'],\n",
        "        'C': [10, 100, 1000]\n",
        "    },\n",
        "    'DecisionTreeClassifier': {\n",
        "        'max_depth': [5, 10, 20]\n",
        "    },\n",
        "    'RandomForestClassifier': {\n",
        "        'n_estimators': [30, 65, 100],\n",
        "        'max_depth': [5, 10, 20]\n",
        "    },\n",
        "    'SVM_Classifier': {\n",
        "        'kernel': ['linear', 'poly', 'rbf'],\n",
        "        'degree': [1, 2],\n",
        "        'C': [10, 100, 1000]\n",
        "    },\n",
        "    'KNN_Classifier': {\n",
        "        'n_neighbors': [20, 50, 80],\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['manhattan', 'euclidean']\n",
        "    },\n",
        "    'ExtraTreesClassifier': {\n",
        "        'n_estimators': [30, 65, 100],\n",
        "        'max_depth': [5, 10, 20]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ouFFHEdkWjDR",
        "outputId": "c985f79c-b620-49e4-e57c-42dc8f03b69a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.]])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = []\n",
        "for i in models:\n",
        "    scores_list = []\n",
        "    scores_list.append(round(cross_val_score(models[i], X_scaled1, Y_balanced, cv=5, scoring='f1').mean(), 2))\n",
        "    scores_list.append(round(cross_val_score(models[i], X_scaled2, Y_balanced, cv=5, scoring='f1').mean(), 2))\n",
        "    scores_list.append(round(cross_val_score(models[i], X_scaled3, Y_balanced, cv=5, scoring='f1').mean(), 2))\n",
        "    scores.append(scores_list)\n",
        "scores = np.array(scores)\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AS ALL SCALINGs ARE GIVING AN EQUAL F1 SCORE FOR ALL MODELS, WE SHALL USE MIN_MAX SCALING (MINIMUM COMPUTATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **STEP-3: MODEL TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **HYPERPARAMETER TUNING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "KP5Ir_lkWjDS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "15 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan  1. nan  1. nan  1.]\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEST SCORE FOR LogisticRegression is 100.0\n",
            "Best parameters: {'C': 10, 'penalty': 'none'}\n",
            "\n",
            "BEST SCORE FOR DecisionTreeClassifier is 100.0\n",
            "Best parameters: {'max_depth': 5}\n",
            "\n",
            "BEST SCORE FOR RandomForestClassifier is 100.0\n",
            "Best parameters: {'max_depth': 5, 'n_estimators': 30}\n",
            "\n",
            "BEST SCORE FOR SVM_Classifier is 100.0\n",
            "Best parameters: {'C': 10, 'degree': 1, 'kernel': 'linear'}\n",
            "\n",
            "BEST SCORE FOR KNN_Classifier is 100.0\n",
            "Best parameters: {'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'uniform'}\n",
            "\n",
            "BEST SCORE FOR ExtraTreesClassifier is 100.0\n",
            "Best parameters: {'max_depth': 5, 'n_estimators': 30}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in models:\n",
        "    current_model = GridSearchCV(models[i], model_params[i], cv = 5, scoring = 'f1')\n",
        "    current_model.fit(X_scaled1, Y_balanced)\n",
        "    print('BEST SCORE FOR {} is {}'.format(i, round(100*current_model.best_score_, 2)))\n",
        "    print('Best parameters:', current_model.best_params_)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AS ALL THE MODELS ARE GIVING A PERFECT F1_SCORE, WE WILL TRAIN, TEST AND EXPORT THE SVM CLASSIFIER BECAUSE IT'S THE FASTEST CLASSIFIER AMONGST THE CHOSEN CLASSIFIERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **SPLITTING TRAINING AND TESTING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled1, Y_balanced, test_size=0.35, stratify=Y_balanced, random_state=453)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    1003\n",
            "1    1003\n",
            "Name: Classification, dtype: int64\n",
            "0    1862\n",
            "1    1862\n",
            "Name: Classification, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(Y_test.value_counts(0))\n",
        "print(Y_train.value_counts(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "lKFlkchHWjDS",
        "outputId": "01cf1cd0-ff4f-47e5-c981-8d0585e11700"
      },
      "outputs": [],
      "source": [
        "SVM_predictor = models['SVM_Classifier']\n",
        "SVM_predictor.fit(X_train, Y_train)\n",
        "predictions = SVM_predictor.predict(X_test)\n",
        "actual = Y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **STEP-4: CLASSIFICATION REPORT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **ACCURACY, F1, PRECISION, RECALL SCORES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "4-J7MZ1rWjDS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score:\t\t 100.0%\n",
            "Precision Score:\t 100.0%\n",
            "Recall Score:\t\t 100.0%\n",
            "F1 Score:\t\t 100.0%\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy Score:\\t\\t {}%'.format(round(100*accuracy_score(actual, predictions), 2)))\n",
        "print('Precision Score:\\t {}%'.format(round(100*precision_score(actual, predictions), 2)))\n",
        "print('Recall Score:\\t\\t {}%'.format(round(100*recall_score(actual, predictions), 2)))\n",
        "print('F1 Score:\\t\\t {}%'.format(round(100*f1_score(actual, predictions), 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **CONFUSION MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MiqErXvgWjDT",
        "outputId": "22f7c0dc-7df4-4b9a-c8d6-608ebcb3847f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Confusion Matrix')\n",
        "sns.heatmap(confusion_matrix(actual, predictions), cmap='Greys_r', annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **STEP-5: EXPORTING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelfile = open('SVM_Classifier', 'ab')\n",
        "pickle.dump(SVM_predictor, modelfile)\n",
        "modelfile.close()\n",
        "\n",
        "scalerfile = open('MinMaxScaler', 'ab')\n",
        "pickle.dump(scaler_minmax, scalerfile)\n",
        "scalerfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **STEP-6: FUNCTION TO PREDICT HEART DISEASE BASED ON CSV_FILE (AND REPORT CLASSIFICATION)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "def heart_predictions(filepath):\n",
        "    #READING DATA\n",
        "    data_raw = pd.read_csv(filepath)\n",
        "    #PASS-1\n",
        "    data_pass1 = pd.get_dummies(data_raw, columns = ['Classification'], drop_first=True)\n",
        "    #PASS-2\n",
        "    data_pass2 = []\n",
        "    for i in range(0, 3500):\n",
        "        wp, measures = hp.process(data_pass1.iloc[i, :-1], sample_rate = 300.0, clean_rr = True,clean_rr_method='z-score',bpmmax=2000,bpmmin=-1000)\n",
        "        values = [i for i in list(measures.values())]\n",
        "        data_pass2.append(np.array(values[0:-1]))\n",
        "    data_pass2 = np.array(data_pass2)\n",
        "    #PASS-3\n",
        "    data_pass3 = pd.DataFrame(data_pass2)\n",
        "    data_pass3['Classification'] = data_pass1['Classification_N']\n",
        "    #PASS-4\n",
        "    data_pass4 = data_pass3.dropna()\n",
        "    data_pass4.isnull().sum()\n",
        "    #PASS-5\n",
        "    data_pass5 = data_pass4.replace((np.inf, -np.inf, np.nan), np.nan).reset_index(drop=True)\n",
        "    data_pass5.dropna(inplace=True)\n",
        "    #BALANCING\n",
        "    smote_balancer = SMOTE(sampling_strategy='minority')\n",
        "    X_balanced, Y_balanced = smote_balancer.fit_resample(data_pass5.drop('Classification', axis=1), data_pass5['Classification'])\n",
        "    data_pass6 = pd.DataFrame(X_balanced)\n",
        "    data_pass6['Classification'] = Y_balanced\n",
        "    #LOADING PICKLED FILES\n",
        "    our_SVM_Classifier = pickle.load(open('SVM_Classifier', 'rb'))\n",
        "    our_MinMaxScaler = pickle.load(open('MinMaxScaler', 'rb'))\n",
        "    #SCALING DATA\n",
        "    X_scaled = our_MinMaxScaler.transform(X_balanced)\n",
        "    #MAKING PREDICTIONS\n",
        "    Y_predictions = our_SVM_Classifier.predict(X_scaled)\n",
        "    #RETURNING F1_SCORE\n",
        "    print(\"F1 Score of the SVM Classifier on our data is: \", f1_score(Y_balanced, Y_predictions))\n",
        "    return Y_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **TESTING ON OUR TRAINING DATA FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:5246: RuntimeWarning: Mean of empty slice.\n",
            "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3757: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\interpolate\\_fitpack2.py:280: UserWarning: \n",
            "The maximal number of iterations maxit (set to 20 by the program)\n",
            "allowed for finding a smoothing spline with fp=s has been reached: s\n",
            "too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  warnings.warn(message)\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23576\\2682068591.py:11: UserWarning: Warning: converting a masked element to nan.\n",
            "  data_pass2.append(np.array(values[0:-1]))\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\interpolate\\_fitpack2.py:280: UserWarning: \n",
            "A theoretically impossible result was found during the iteration\n",
            "process for finding a smoothing spline with fp = s: s too small.\n",
            "There is an approximation returned but the corresponding weighted sum\n",
            "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score of the SVM Classifier on our data is:  1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 0], dtype=uint8)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_predictions('ECG_Training.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ECG_Flipr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
